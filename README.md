# TAMIGO: Empowering Teaching Assistants using LLM-assisted viva and code assessment in an Advanced Computing Class

## Abstract

Large Language Models (LLMs) have significantly transformed the
educational landscape, offering new tools for students, instructors,
and teaching assistants. This paper investigates the application
of LLMs in assisting teaching assistants (TAs) with viva and code
assessments in an advanced computing class on distributed systems
in an Indian University. We develop TAMIGO, an LLM-based system
for TAs to evaluate programming assignments.
For viva assessment, the TAs generated questions using TAMIGO
and circulated these questions to the students for answering. The
TAs then used TAMIGO to generate feedback on student answers.
For code assessment, the TAs selected specific code blocks from
student code submissions and fed it to TAMIGO to generate feed-
back for these code blocks. The TAMIGO-generated feedback for
student answers and code blocks was used by the TAs for further
evaluation.
We evaluate the quality of LLM-generated viva questions, model
answers, feedback on viva answers, and feedback on student code
submissions. Our results indicate that LLMs are highly effective
at generating viva questions when provided with sufficient con-
text and background information. However, the results for LLM-
generated feedback on viva answers were mixed; instances of hallu-
cination occasionally reduced the accuracy of feedback. Despite this,
the feedback was consistent, constructive, comprehensive, balanced,
and did not overwhelm the TAs. Similarly, for code submissions,
the LLM-generated feedback was constructive, comprehensive and
balanced, though there was room for improvement in aligning the
feedback with the instructor-provided rubric for code evaluation.
Our findings contribute to understanding the benefits and limita-
tions of integrating LLMs into educational settings.